{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1 (я писал прямо в тетрадке Ngrams с занятия)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Языковое моделирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Языковое моделирование заключается в приписывании вероятности последовательности слов. Сейчас языковые модели используются практически во всех nlp задачах. Всякие Берты и Элмо - языковые модели. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это достаточно сложная тема, поэтому будем разбирать постепенно. Сегодня разберём самые основы. Научимся приписывать вероятность последовательности слов и попробуем генерировать текст."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем два разных корпуса: новостной и сообщения с 2ch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! двач не самое приятное место, большое количество текстов в этом корпусе токсичные\n",
    "dvach = open('data/2ch_corpus.txt', encoding='utf8').read()[:700000]\n",
    "# !!! двач не самое приятное место, большое количество текстов в этом корпусе токсичные\n",
    "\n",
    "news = open('data/lenta.txt', encoding='utf8').read()[:700000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По длине оно сопоставимы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина 1 - 700000\n",
      "Длина 2 - 700000\n"
     ]
    }
   ],
   "source": [
    "print(\"Длина 1 -\", len(dvach))\n",
    "print(\"Длина 2 -\", len(news))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем простую функцию для нормализации. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from razdel import sentenize\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "import numpy as np\n",
    "\n",
    "def normalize(text):\n",
    "    normalized_text = [word.text.strip(punctuation) for word \\\n",
    "                                                            in razdel_tokenize(text)]\n",
    "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n",
    "    return normalized_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним тексты по токенам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_dvach = normalize(dvach)[:500000]\n",
    "norm_news = normalize(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина корпуса токсичных постов в токенах - 110912\n",
      "Длина корпуса новостных текстов в токенах -  90323\n"
     ]
    }
   ],
   "source": [
    "print(\"Длина корпуса токсичных постов в токенах -\", len(norm_dvach))\n",
    "print(\"Длина корпуса новостных текстов в токенах - \", len(norm_news))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И по уникальным токенам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальных токенов в корпусе токсичных постов - 26166\n",
      "Уникальный токенов в корпусе новостных текстов -  22569\n"
     ]
    }
   ],
   "source": [
    "print(\"Уникальных токенов в корпусе токсичных постов -\", len(set(norm_dvach)))\n",
    "print(\"Уникальный токенов в корпусе новостных текстов - \", len(set(norm_news)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем, сколько раз встречаются слова и выведем самые частотные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dvach = Counter(norm_dvach)\n",
    "vocab_news = Counter(norm_news)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('и', 3144),\n",
       " ('в', 2921),\n",
       " ('не', 2736),\n",
       " ('на', 1927),\n",
       " ('что', 1623),\n",
       " ('а', 1266),\n",
       " ('я', 1223),\n",
       " ('с', 1171),\n",
       " ('это', 1078),\n",
       " ('как', 978)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dvach.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('в', 4264),\n",
       " ('и', 2145),\n",
       " ('на', 1643),\n",
       " ('по', 1214),\n",
       " ('что', 1042),\n",
       " ('с', 996),\n",
       " ('не', 813),\n",
       " ('как', 534),\n",
       " ('из', 482),\n",
       " ('о', 448)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_news.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнивать употребимость конкретных слов в разных текстах в абсолютных числах неудобно. Нормализуем счётчики на размеры текстов. Так у нас получается вероятность слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('и', 0.0283467974610502),\n",
       " ('в', 0.026336194460473167),\n",
       " ('не', 0.024668205424120022),\n",
       " ('на', 0.017374134448932488),\n",
       " ('что', 0.014633222735141373),\n",
       " ('а', 0.011414454702827467),\n",
       " ('я', 0.011026759953837277),\n",
       " ('с', 0.010557919792267743),\n",
       " ('это', 0.009719417195614541),\n",
       " ('как', 0.008817801500288517),\n",
       " ('ты', 0.008276832083092902),\n",
       " ('но', 0.006149019042123486),\n",
       " ('у', 0.006067873629544143),\n",
       " ('то', 0.005788372763993075),\n",
       " ('по', 0.0051121609924985574),\n",
       " ('так', 0.005031015579919215),\n",
       " ('все', 0.004868724754760531),\n",
       " ('если', 0.00482364396999423),\n",
       " ('же', 0.004183496826312753),\n",
       " ('для', 0.00409333525678015)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas_dvach = Counter({word:c/len(norm_dvach) for word, c in vocab_dvach.items()})\n",
    "probas_dvach.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('в', 0.047208352246935995),\n",
       " ('и', 0.023748104026659875),\n",
       " ('на', 0.018190272688019662),\n",
       " ('по', 0.013440651882687688),\n",
       " ('что', 0.011536375009687455),\n",
       " ('с', 0.01102709165993158),\n",
       " ('не', 0.00900102963807668),\n",
       " ('как', 0.005912115408035605),\n",
       " ('из', 0.0053364037952680935),\n",
       " ('о', 0.00495997697153549),\n",
       " ('к', 0.003952481649192343),\n",
       " ('россии', 0.003897124763349313),\n",
       " ('за', 0.003697839974314405),\n",
       " ('для', 0.0033103417734131947),\n",
       " ('он', 0.003144271115884105),\n",
       " ('от', 0.003055700098535257),\n",
       " ('его', 0.0029560577040178026),\n",
       " ('также', 0.002878558063837561),\n",
       " ('сша', 0.0025796308802851988),\n",
       " ('а', 0.0025574881259479865)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas_news = Counter({word:c/len(norm_news) for word, c in vocab_news.items()})\n",
    "probas_news.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти вероятности уже можно использовать, чтобы ответить на вопрос - это предложение больше подходит для новостей или для анонимного форума?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = 'Бои у Сопоцкина и Друскеник закончились отступлением германцев'\n",
    "\n",
    "prob = Counter({'news':0, 'dvach':0})\n",
    "\n",
    "for word in normalize(phrase):\n",
    "    prob['dvach'] += probas_dvach.get(word, 0)\n",
    "    prob['news'] += probas_news.get(word, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dvach', 0.034414671090594345), ('news', 0.025430953356287988)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = 'как вы смотрите эту залупу, серьезно. в чем прикол ваще это смотреть?'\n",
    "\n",
    "prob = Counter({'news':0, 'dvach':0})\n",
    "\n",
    "for word in normalize(phrase):\n",
    "    prob['dvach'] += probas_dvach.get(word, 0)\n",
    "    prob['news'] += probas_news.get(word, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('news', 0.05629795290236152), ('dvach', 0.04891265147143682)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты получаются не очень точные. Возможно это из-за того, что мы считаем слова независимыми друг от друга. А это очевидно не так"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По-хорошему вероятность последовательности нужно расчитывать по формуле полной вероятности. Но у нас не очень большие тексты и мы не можем получить вероятности для длинных фраз (их просто может не быть в текстах). Поэтому мы воспользуемся предположением Маркова и будем учитывать только предыдущее слово."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы расчитать вероятность с таким предположением, нам достаточно найти количество вхождений для каждого биграмма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "def ngrammer(tokens, n=3):\n",
    "    ngrams = []\n",
    "    for i in range(0,len(tokens)-n+1):\n",
    "        ngrams.append(' '.join(tokens[i:i+n]))\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы у нас получились честные вероятности и можно было посчитать вероятность первого слова, нам нужно добавить тэг маркирующий начало предложений \\< start \\>\n",
    "\n",
    "Дальше мы попробуем сгенерировать текст, используя эти вероятности, и нам нужно будет когда-то остановится. Для этого добавим тэг окончания \\< end \\>\n",
    "\n",
    "Ну и поделим все на предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_dvach = [['<start>', '<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(dvach)]\n",
    "sentences_news = [['<start>', '<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(news)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams_dvach = Counter()\n",
    "nminusonegrams_dvach = Counter()\n",
    "ngrams_dvach = Counter()\n",
    "\n",
    "for sentence in sentences_dvach:\n",
    "    unigrams_dvach.update(sentence)\n",
    "    nminusonegrams_dvach.update(ngrammer(sentence, n=n-1)) #вот тут создаётся лишняя биграмма слово end, для которой нет триграммы\n",
    "    ngrams_dvach.update(ngrammer(sentence))\n",
    "\n",
    "unigrams_news = Counter()\n",
    "nminusonegrams_news = Counter()\n",
    "ngrams_news = Counter()\n",
    "\n",
    "for sentence in sentences_news:\n",
    "    unigrams_news.update(sentence)\n",
    "    nminusonegrams_news.update(ngrammer(sentence, n=n-1))\n",
    "    ngrams_news.update(ngrammer(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26168"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unigrams_dvach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<start> <start> в', 408),\n",
       " ('<start> <start> по', 350),\n",
       " ('<start> <start> как', 250),\n",
       " ('<start> <start> на', 115),\n",
       " ('<start> <start> об', 90),\n",
       " ('<start> <start> однако', 86),\n",
       " ('<start> об этом', 86),\n",
       " ('<start> по словам', 82),\n",
       " ('<start> как сообщает', 77),\n",
       " ('<start> <start> он', 67)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_news.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы посчитать условную вероятность мы можем поделить количество вхождений на количество вхождений первых n-1 слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase =  'Бои у Сопоцкина и Друскеник закончились отступлением германцев'\n",
    "# phrase = 'как вы смотрите эту залупу, серьезно. в чем прикол ваще это смотреть?'\n",
    "prob = Counter()\n",
    "for ngram in ngrammer(['<start>', '<start>'] + normalize(phrase) + ['<end>']):\n",
    "    words = ngram.split()\n",
    "    \n",
    "    word1 = ' '.join(words[:-1])\n",
    "    \n",
    "    if word1 in nminusonegrams_dvach and ngram in ngrams_dvach:\n",
    "        prob['dvach'] += np.log(ngrams_dvach[ngram]/nminusonegrams_dvach[word1])\n",
    "    else:\n",
    "        prob['dvach'] += np.log(0.001)\n",
    "    \n",
    "    if word1 in nminusonegrams_news and ngram in ngrams_news:\n",
    "        prob['news'] += np.log(ngrams_news[ngram]/nminusonegrams_news[word1])\n",
    "    else:\n",
    "        prob['news'] += np.log(0.001)\n",
    "\n",
    "prob['news'] = np.exp(prob['news'])\n",
    "prob['dvach'] = np.exp(prob['dvach'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('news', 0.00021920210434020194), ('dvach', 1.0000000000000022e-27)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работает получше. Мы воспользовались небольшим хаком - для слов или биграммов, которых не было у нас в словаре, прибавляли низкую вероятность. Исправить это по-нормальному - сложно, придется подробнее разбираться с вероятностями, сглаживаниями и заменой неизвестных слов. Если интрересно - в книге Журафского про это есть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблем с неизвестными словами у нас не будет, если мы будем пытаться сгенерировать новый текст. Давайте попробуем это сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_dvach = np.zeros((len(nminusonegrams_dvach), \n",
    "                   len(unigrams_dvach)))\n",
    "id2gram_dvach = list(nminusonegrams_dvach)\n",
    "gram2id_dvach = {gram:i for i, gram in enumerate(id2gram_dvach)}\n",
    "\n",
    "id2word_dvach = list(unigrams_dvach)\n",
    "word2id_dvach = {word:i for i, word in enumerate(id2word_dvach)}\n",
    "\n",
    "for ngram in ngrams_dvach:\n",
    "    words = ngram.split()\n",
    "    word1 = ' '.join(words[:-1])\n",
    "    last_word = words[-1]\n",
    "    \n",
    "    matrix_dvach[gram2id_dvach[word1]][word2id_dvach[last_word]] =  (ngrams_dvach[ngram]/\n",
    "                                                                     nminusonegrams_dvach[word1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим матрицу вероятностей перейти из 1 слов в другое\n",
    "matrix_news = np.zeros((len(nminusonegrams_news), \n",
    "                   len(unigrams_news)))\n",
    "id2gram_news = list(nminusonegrams_news) \n",
    "gram2id_news = {gram:i for i, gram in enumerate(id2gram_news)}\n",
    "\n",
    "id2word_news = list(unigrams_news)\n",
    "word2id_news = {word:i for i, word in enumerate(id2word_news)} \n",
    "\n",
    "\n",
    "# вероятность расчитываем точно также\n",
    "for ngram in ngrams_news:\n",
    "    words = ngram.split()\n",
    "    word1 = ' '.join(words[:-1])\n",
    "    last_word = words[-1]\n",
    "    \n",
    "    matrix_news[gram2id_news[word1]][word2id_news[last_word]] =  (ngrams_news[ngram]/\n",
    "                                                                     nminusonegrams_news[word1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для генерации нам понадобится функция np.random.choice , которая выбирает случайный объект из заданных. Ещё в неё можно подать вероятность каждого объекта и она будет доставать по ним (не только максимальный по вероятности)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate(matrix, id2word, gram2id, id2gram, n=100, start='<start> <start>'):\n",
    "    text = []\n",
    "    current_idx = gram2id[start]\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        chosen = np.random.choice(matrix.shape[1], p=matrix[current_idx])\n",
    "        text.append(id2word[chosen])\n",
    "        \n",
    "        if id2word[chosen] == '<end>':\n",
    "            chosen = '<start> <start>'\n",
    "            current_x = chosen\n",
    "        else:\n",
    "            current_x = ' '.join(id2gram[current_idx].split()[1:]) + ' ' + id2word[chosen]\n",
    "        current_idx =  gram2id[current_x]\n",
    "    \n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "а как минимум неудобно \n",
      " даже даун маск в секторе it смог в своё время ебало мамку омегосущества и твою скорее всего платят очень мало времени уделяешь языку \n",
      " лейтенант отобрал твой значок потому что случай как говорит тяжелый и предлагает ехать или в оон опустят \n",
      " а что такое издач с такой завязкой ничего нормального не получится \n",
      " цыпа хороша да \n",
      " уж очень не хочется же сливать в голивудщину когда после главы эдакое to be continued \n",
      " если смотреть без перспективы и перпендикулярно т е мир на земле был бы изобрести ту вещь \n",
      " хоронили арсекеда спалили два\n"
     ]
    }
   ],
   "source": [
    "print(generate(matrix_dvach, id2word_dvach, gram2id_dvach, id2gram_dvach).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "повидимому под обломками также оказались десятки припаркованных неподалеку автомашин \n",
      " такие учения проводятся не только в россии досрочных президентских выборов в йемене погибйеменец передало агентство риа новости впосольстве рф в дагестане лужков не исключил фактор мщения со стороны руководящего состава за организацией несения службы передает итар-тасс по словам рушайло взрывчатка обнаружена уже после утреннего взрыва на манежной площади в центре управления полетом в пасадене \n",
      " как предполагает мк семья ельцина начинает понимать что немощный старик у руля государства опасен не только на 3 суток работы \n",
      " путин высказался также за парковкой возле домов \n",
      " это произойдет если будет хозяина склада\n"
     ]
    }
   ],
   "source": [
    "print(generate(matrix_news, id2word_news, gram2id_news, id2gram_news).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2 (тут копировал куски из тетрадки про коллокации)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from razdel import sentenize\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "import re\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stops = set(stopwords.words('russian') + [\"это\", \"весь\"])\n",
    "morph = MorphAnalyzer()\n",
    "\n",
    "def normalize(text):\n",
    "    tokens = re.findall('[а-яёa-z0-9]+', text.lower())\n",
    "    normalized_text = [morph.parse(word)[0].normal_form for word \\\n",
    "                                                            in tokens]\n",
    "    normalized_text = [word for word in normalized_text if len(word) > 2 and word not in stops]\n",
    "    \n",
    "    return normalized_text\n",
    "\n",
    "def preprocess(text):\n",
    "    sents = sentenize(text)\n",
    "    return [normalize(sent.text) for sent in sents]\n",
    "\n",
    "def ngrammer(tokens, stops, n=2):\n",
    "    ngrams = []\n",
    "    tokens = [token for token in tokens if token not in stops]\n",
    "    for i in range(0,len(tokens)-n+1):\n",
    "        ngrams.append(tuple(tokens[i:i+n]))\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = open('data/lenta.txt', encoding='utf8').read()[:500000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = preprocess(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Моя функция "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_scorer(worda_count, wordb_count, bigram_count, len_vocab, min_count, corpus_word_count):\n",
    "    try:\n",
    "        if bigram_count - min_count > 0: #сразу выкинем низкочастотные биграммы\n",
    "            score_ = (pow(bigram_count - min_count, 1.1) * len_vocab / ((worda_count * wordb_count))) #чуть-чуть увеличим вес биграммы\n",
    " #           score_ = math.log(score_, 2) с этой строкой (и return float('-inf') ниже) почему-то была ошибка с трешхолдом меньше -1\n",
    "        else:\n",
    "            return 0\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "    \n",
    "    return score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_stats(corpus, stops):\n",
    "    ## соберем статистики для отдельных слов\n",
    "    ## и n-грамм\n",
    "    \n",
    "    unigrams = Counter()\n",
    "    bigrams = Counter()\n",
    "    \n",
    "    for sent in corpus:\n",
    "        unigrams.update(sent)\n",
    "        bigrams.update(ngrammer(sent, stops, n=2))\n",
    "    \n",
    "    return unigrams, bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_bigrams(unigrams, bigrams, scorer, threshold=float('-inf'), min_count=3):\n",
    "    ## посчитаем метрику для каждого нграмма\n",
    "    bigram2score = Counter()\n",
    "    len_vocab = len(unigrams)\n",
    "    for bigram in bigrams:\n",
    "        score = scorer(unigrams[bigram[0]], unigrams[bigram[1]], \n",
    "                       bigrams[bigram], len_vocab, min_count, None)\n",
    "        \n",
    "        ## если метрика выше порога, добавляем в словарик\n",
    "        if score > threshold:\n",
    "            bigram2score[bigram] = score\n",
    "    \n",
    "    return bigram2score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams, bigrams = collect_stats(corpus, stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram2score = score_bigrams(unigrams, bigrams, my_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('дель', 'понтить'), 805.2877088112692),\n",
       " (('буэнос', 'айрес'), 805.2877088112692),\n",
       " (('луис', 'фри'), 805.2877088112692),\n",
       " (('usa', 'today'), 748.7592036090309),\n",
       " (('della', 'sera'), 731.2440615543088),\n",
       " (('corriere', 'della'), 700.7823230385126),\n",
       " (('геннадий', 'селезнёв'), 641.7936030934551),\n",
       " (('кубический', 'сантиметр'), 599.3652750073419),\n",
       " (('сан', 'франциско'), 587.0),\n",
       " (('петербургский', 'стиль'), 587.0),\n",
       " (('grand', 'сentral'), 587.0),\n",
       " (('борисовский', 'пруд'), 587.0),\n",
       " (('associated', 'press'), 576.1540215185414),\n",
       " (('холерный', 'вибрион'), 575.2055062937637),\n",
       " (('вынужденный', 'переселенец'), 575.2055062937637),\n",
       " (('каширский', 'шоссе'), 535.1723785175188),\n",
       " (('стихийный', 'бедствие'), 530.3856304558979),\n",
       " (('взрывчатый', 'вещество'), 506.24588876836765),\n",
       " (('исполнять', 'обязанность'), 471.45389373857586),\n",
       " (('шкала', 'рихтер'), 469.6)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram2score.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генсим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# собираем статистики\n",
    "ph = gensim.models.Phrases(corpus, min_count=3, threshold=-1, scoring=my_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразовывать можно и через ph, но так быстрее \n",
    "p = gensim.models.phrases.Phraser(ph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['штаб_поддержка',\n",
       " 'владимир_семёнов',\n",
       " 'отмечать_прокуратура',\n",
       " 'министерство_внутренний',\n",
       " 'дело_карачаево',\n",
       " 'черкесия_практически',\n",
       " 'принимать_мера',\n",
       " 'пресечение_подобный',\n",
       " 'действие_организовать',\n",
       " 'лишь_оцепление',\n",
       " 'омон_здание',\n",
       " 'правительство_состояться',\n",
       " 'сегодня_москва',\n",
       " 'пресс_конференция',\n",
       " 'бывший_шеф']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[corpus[157]][:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "поднимем порог (тут я не видно попыток с другими порогами, потому что я запускал их в том же фрейме, а видно сразу результат)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['штаб',\n",
       " 'поддержка',\n",
       " 'владимир_семёнов',\n",
       " 'отмечать',\n",
       " 'прокуратура',\n",
       " 'министерство',\n",
       " 'внутренний_дело',\n",
       " 'карачаево_черкесия',\n",
       " 'практически',\n",
       " 'принимать',\n",
       " 'мера',\n",
       " 'пресечение',\n",
       " 'подобный',\n",
       " 'действие',\n",
       " 'организовать']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ph = gensim.models.Phrases(corpus, min_count=3, threshold=125, scoring=my_scorer)\n",
    "p = gensim.models.phrases.Phraser(ph)\n",
    "p[corpus[157]][:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хотелось бы конечно штаб_поддержка и мера_пресечения, но они не проходят min_count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# собираем статистики по уже забиграммленному тексту\n",
    "ph2 = gensim.models.Phrases(p[corpus], min_count=3, threshold=125, scoring=my_scorer)\n",
    "p2 = gensim.models.phrases.Phraser(ph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['штаб',\n",
       " 'поддержка',\n",
       " 'владимир_семёнов',\n",
       " 'отмечать',\n",
       " 'прокуратура',\n",
       " 'министерство_внутренний_дело',\n",
       " 'карачаево_черкесия',\n",
       " 'практически',\n",
       " 'принимать',\n",
       " 'мера',\n",
       " 'пресечение',\n",
       " 'подобный',\n",
       " 'действие',\n",
       " 'организовать',\n",
       " 'лишь']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2[p[corpus[157]]][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "На этом куске получилось вполне нормально, министерство_внутренних_дел склеилось как надо. Попробуем на другом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['заявить',\n",
       " 'сегодня',\n",
       " 'встреча',\n",
       " 'премьер_министр',\n",
       " 'япония',\n",
       " 'вица_премьер',\n",
       " 'правительство',\n",
       " 'россия',\n",
       " 'виктор',\n",
       " 'христенко']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[corpus[57]][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['заявить',\n",
       " 'сегодня',\n",
       " 'встреча',\n",
       " 'премьер_министр',\n",
       " 'япония',\n",
       " 'вица_премьер',\n",
       " 'правительство',\n",
       " 'россия',\n",
       " 'виктор',\n",
       " 'христенко']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2[p[corpus[57]]][:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут немного похуже(потерялся виктор_христенко и правительство_россии), но зато есть вице_премьер (который не склеился с японией) и премьер_министр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
